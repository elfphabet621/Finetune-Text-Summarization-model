{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctN351tB5odU"
      },
      "source": [
        "# Summarization (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPl27vzw5ode"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece] -qq\n",
        "!pip install accelerate -qq\n",
        "!pip install rouge_score -qq\n",
        "!pip install nltk -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "IxjycLWXdF8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, concatenate_datasets, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import evaluate\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "euJLtsnudHle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Args"
      ],
      "metadata": {
        "id": "j7qfdoHYdvUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 30\n",
        "batch_size = 8\n",
        "num_train_epochs = 10"
      ],
      "metadata": {
        "id": "9Ogcz6MJdwJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download + Preprocess data"
      ],
      "metadata": {
        "id": "DQH32luVU_dk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9ZQKvxV5odm"
      },
      "outputs": [],
      "source": [
        "train_ds_size = 5000\n",
        "test_ds_size = 1000\n",
        "\n",
        "vietnamese_train_ds, vietnamese_test_ds = load_dataset(\"wiki_lingua\", \"vietnamese\", \n",
        "                                                       split=[f'train[:{train_ds_size}]', f'train[{train_ds_size}:{train_ds_size+test_ds_size}]'])\n",
        "\n",
        "english_train_ds, english_test_ds = load_dataset(\"wiki_lingua\", \"english\", \n",
        "                                                 split=[f'train[:{train_ds_size}]', f'train[{train_ds_size}:{train_ds_size+test_ds_size}]'])\n",
        "\n",
        "def preporcess_columns_data_type(ds):\n",
        "  ds = pd.DataFrame(data=ds['article'])\n",
        "  ds['document'] = ds['document'].apply(lambda x: ' '.join(x))\n",
        "  ds['summary'] = ds['summary'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "  return ds\n",
        "\n",
        "def parse_dataset(ds_train, ds_test):\n",
        "  ds_train = preporcess_columns_data_type(ds_train)\n",
        "  ds_train = Dataset.from_pandas(ds_train)\n",
        "\n",
        "  ds_test = preporcess_columns_data_type(ds_test)\n",
        "  ds_test = Dataset.from_pandas(ds_test)\n",
        "\n",
        "  return ds_train, ds_test\n",
        "\n",
        "english_train_ds, english_test_ds = parse_dataset(english_train_ds, english_test_ds)\n",
        "vietnamese_train_ds, vietnamese_test_ds = parse_dataset(vietnamese_train_ds, vietnamese_test_ds)\n",
        "english_train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbSXNcdo5odo"
      },
      "outputs": [],
      "source": [
        "def show_samples(dataset, num_samples=3, seed=42):\n",
        "  sample = dataset.shuffle(seed=seed).select(range(num_samples))\n",
        "\n",
        "  for example in sample:\n",
        "      print(f\"\\n'>> Document: {example['document']}'\")\n",
        "      print(f\"'>> Summary: {example['summary']}'\")\n",
        "\n",
        "show_samples(english_train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDc-3XCz5odt"
      },
      "outputs": [],
      "source": [
        "dataset = DatasetDict()\n",
        "\n",
        "def concat_two_datasets(dataset1, dataset2):\n",
        "  dataset = concatenate_datasets([dataset1, dataset2])\n",
        "  dataset = dataset.shuffle(seed=42)\n",
        "  return dataset\n",
        "\n",
        "dataset['train'] = concat_two_datasets(english_train_ds, vietnamese_train_ds)\n",
        "dataset['test'] = concat_two_datasets(english_test_ds, vietnamese_test_ds)\n",
        "\n",
        "show_samples(dataset['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA + Filter data"
      ],
      "metadata": {
        "id": "fdzOvaMKVIUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_len(x):\n",
        "  return len(x.split())\n",
        "\n",
        "dataset.set_format(\"pandas\")\n",
        "df = dataset['train'][:]\n",
        "\n",
        "df[\"length\"] = df['document'].apply(get_len)\n",
        "\n",
        "df[\"length\"].sort_values(ascending=False).plot(kind='hist')"
      ],
      "metadata": {
        "id": "1sWHiD5FIuz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.reset_format()\n",
        "dataset = dataset.filter(lambda x: get_len(x['document']) < 550)\n",
        "dataset = dataset.filter(lambda x: get_len(x['summary']) > 2 and get_len(x['summary']) < 45)\n",
        "dataset"
      ],
      "metadata": {
        "id": "b1JsoksdN2ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric"
      ],
      "metadata": {
        "id": "987cASWVVc1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPUgbACk5odz"
      },
      "outputs": [],
      "source": [
        "rouge_score = evaluate.load(\"rouge\")\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "T8EaJK0PVlNd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjv6Q6im5od2"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"google/mt5-small\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "dOZflWWgVM4F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mturQtN95odw"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(examples[\"document\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True)\n",
        "    \n",
        "    labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "q0ARflJZa5pM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASbfwhQf5od5"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched=True, batch_size=64)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(\n",
        "    dataset[\"train\"].column_names)\n",
        "tokenized_datasets.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "QXY-DMtoVzTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJGSvv-35od5"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size,)\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "CZ4r5fvXV9v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
      ],
      "metadata": {
        "id": "KvqOuWD4eUCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLFRcqpv5od6"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scheduler"
      ],
      "metadata": {
        "id": "Jp3BMPtmV4CF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aD2JC9rM5od7"
      },
      "outputs": [],
      "source": [
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRyJuZZ85od7"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train + Eval"
      ],
      "metadata": {
        "id": "K6t5OFS2IE8D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HWXAPOpt5od8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "c6ba754fa9b544a488243cf334c01572",
            "627e5b96444e4cc998f377c694caf7aa",
            "6cc0a7463f854e5790315751cae9b477",
            "0485faa538c94b0ba6957c08fe1dd5c2",
            "00b3a98a72ed40ba90674ec99c0131b1",
            "4b689a34b6e24617b6a208d9c2d44d1d",
            "d61690ac75dd460398b180331d2f3c31",
            "ceb5eb920d304bc0ad2bb9f39770ce07",
            "99eedf814ebd480eb038d29a1b94d480",
            "251f65fc1b0f468998252b9a687ad25f",
            "5e24c7bec6a247d2b8a683404f1f7153"
          ]
        },
        "outputId": "d93f3724-7349-4040-c7c5-fd4a5fcd5481"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/710 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6ba754fa9b544a488243cf334c01572"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10: {'rouge1': 16.9757, 'rouge2': 5.1833, 'rougeL': 14.9742, 'rougeLsum': 15.7201}\n",
            "Epoch 2 / 10: {'rouge1': 16.9899, 'rouge2': 5.224, 'rougeL': 15.0307, 'rougeLsum': 15.845}\n",
            "Epoch 3 / 10: {'rouge1': 17.8864, 'rouge2': 5.6078, 'rougeL': 15.2309, 'rougeLsum': 16.4326}\n",
            "Epoch 4 / 10: {'rouge1': 17.641, 'rouge2': 5.5965, 'rougeL': 15.0372, 'rougeLsum': 16.29}\n",
            "Epoch 5 / 10: {'rouge1': 18.0917, 'rouge2': 5.645, 'rougeL': 15.3974, 'rougeLsum': 16.6957}\n",
            "Epoch 6 / 10: {'rouge1': 17.8797, 'rouge2': 5.4575, 'rougeL': 15.2241, 'rougeLsum': 16.4437}\n",
            "Epoch 7 / 10: {'rouge1': 17.9234, 'rouge2': 5.5306, 'rougeL': 15.1526, 'rougeLsum': 16.48}\n",
            "Epoch 8 / 10: {'rouge1': 17.9172, 'rouge2': 5.5306, 'rougeL': 15.0623, 'rougeLsum': 16.3199}\n",
            "Epoch 9 / 10: {'rouge1': 17.9391, 'rouge2': 5.6348, 'rougeL': 15.2106, 'rougeLsum': 16.0324}\n",
            "Epoch 10 / 10: {'rouge1': 18.2028, 'rouge2': 5.72, 'rougeL': 15.3121, 'rougeLsum': 16.1298}\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
        "                batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                max_new_tokens=30\n",
        "            )\n",
        "\n",
        "            generated_tokens = accelerator.pad_across_processes(\n",
        "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
        "            )\n",
        "            labels = batch[\"labels\"]\n",
        "\n",
        "            # If we did not pad to max length, we need to pad the labels too\n",
        "            labels = accelerator.pad_across_processes(\n",
        "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
        "            labels = accelerator.gather(labels).cpu().numpy()\n",
        "\n",
        "            # Replace -100 in the labels as we can't decode them\n",
        "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "            if isinstance(generated_tokens, tuple):\n",
        "                generated_tokens = generated_tokens[0]\n",
        "            decoded_preds = tokenizer.batch_decode(\n",
        "                generated_tokens, skip_special_tokens=True\n",
        "            )\n",
        "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            decoded_preds, decoded_labels = postprocess_text(\n",
        "                decoded_preds, decoded_labels\n",
        "            )\n",
        "\n",
        "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    result = rouge_score.compute()\n",
        "    result ={key: round(value * 100, 4) for key, value in result.items()}\n",
        "    print(f\"Epoch {epoch+1} / {num_train_epochs}:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "hd49az_qFRoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = 'mt5-finetuned-summarization'\n",
        "\n",
        "accelerator.wait_for_everyone()\n",
        "unwrapped_model = accelerator.unwrap_model(model)\n",
        "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "if accelerator.is_main_process:\n",
        "  tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "6DzmYkqRoGjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "IKFKar6qUjN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"\"\"Tìm máy nghiền gốc cây. Đào xung quanh rễ cây. \n",
        "Tìm hiểu xem có được phép đốt gốc cây trong khu vực bạn ở không. Giữ cho trẻ em và vật nuôi tránh xa gốc cây. Thay thế tro bằng đất mùn.\"\"\"\n",
        "\n",
        "def preprocess_txt(examples):\n",
        "    model_inputs=tokenizer(\n",
        "    examples,\n",
        "    max_length=512,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\")\n",
        "\n",
        "    return model_inputs\n",
        "    \n",
        "input_example = preprocess_txt(doc)\n",
        "input_example = input_example.to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  generated_tokens = accelerator.unwrap_model(model).generate(\n",
        "      input_ids=input_example[\"input_ids\"],\n",
        "      attention_mask=input_example[\"attention_mask\"],\n",
        "      num_beams=2,\n",
        "      max_length=30,\n",
        "      repetition_penalty=2.5,\n",
        "      length_penalty=2.0,\n",
        "      early_stopping=True,\n",
        "      use_cache=True\n",
        "  )\n",
        "\n",
        "preds=[tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
        "         for gen_id in generated_tokens]\n",
        "\n",
        "summary = \"\".join(preds)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "tURo5LCnIIuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23eb9ad-306c-4300-ba40-308a898b4909"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đốt gốc cây.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6ba754fa9b544a488243cf334c01572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_627e5b96444e4cc998f377c694caf7aa",
              "IPY_MODEL_6cc0a7463f854e5790315751cae9b477",
              "IPY_MODEL_0485faa538c94b0ba6957c08fe1dd5c2"
            ],
            "layout": "IPY_MODEL_00b3a98a72ed40ba90674ec99c0131b1"
          }
        },
        "627e5b96444e4cc998f377c694caf7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b689a34b6e24617b6a208d9c2d44d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_d61690ac75dd460398b180331d2f3c31",
            "value": "100%"
          }
        },
        "6cc0a7463f854e5790315751cae9b477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb5eb920d304bc0ad2bb9f39770ce07",
            "max": 710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99eedf814ebd480eb038d29a1b94d480",
            "value": 710
          }
        },
        "0485faa538c94b0ba6957c08fe1dd5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_251f65fc1b0f468998252b9a687ad25f",
            "placeholder": "​",
            "style": "IPY_MODEL_5e24c7bec6a247d2b8a683404f1f7153",
            "value": " 710/710 [06:42&lt;00:00,  2.46it/s]"
          }
        },
        "00b3a98a72ed40ba90674ec99c0131b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b689a34b6e24617b6a208d9c2d44d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d61690ac75dd460398b180331d2f3c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceb5eb920d304bc0ad2bb9f39770ce07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99eedf814ebd480eb038d29a1b94d480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "251f65fc1b0f468998252b9a687ad25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e24c7bec6a247d2b8a683404f1f7153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
